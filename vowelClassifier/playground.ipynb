{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import librosa.display\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from utils import *\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://jonathan-hui.medium.com/speech-recognition-phonetics-d761ea1710c0\n",
    "\n",
    "TIMIT: https://www.kaggle.com/mfekadu/darpa-timit-acousticphonetic-continuous-speech"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "class TIMIT():\n",
    "    def __init__(self, TIMIT_path):\n",
    "        # path of CVS files\n",
    "        self.dirPath = TIMIT_path + \"/\"\n",
    "        self.metadataCSVpath = self.dirPath + \"train_data.csv\"\n",
    "        # CVS dataframes\n",
    "        self.metadata = None\n",
    "        self.metadataWave = None\n",
    "\n",
    "        self.audio_MFCC = []        # audio frames in MFCC\n",
    "        self.audio_Phoncode = []    # audio frames's corresponding phoncodes\n",
    "        self.audio_t = []           # time stamp for each audio frame\n",
    "        self.audio_t_labels = []    # each audio frames' phoncodes converted to numbers\n",
    "        self.audio_t_labels_binary = []    # each audio frames' phoncodes converted to numbers based on vowel/non-vowel\n",
    "        self.audio_t_labels_type = []    # each audio frames' phoncodes converted to numbers based on type\n",
    "        self.phonDict = None        # key: phoncode, value: phoncode types\n",
    "        self.phon2num = None        # key: phonecode, value: integers\n",
    "        self.type2num = None        # key: type, value: type integers\n",
    "        self.sr = None              # sampling rate\n",
    "\n",
    "        def get_phonDict(file):\n",
    "            '''\n",
    "            input\n",
    "                file: phoncode dictionary file variable\n",
    "            output\n",
    "                phonDict: key: phoncode, value: phoncode types\n",
    "                phon2num_dict: key: phonecode, value: integers\n",
    "            '''\n",
    "            lines = file.readlines()\n",
    "            phonDict = {}\n",
    "            phon2num_dict = {}\n",
    "            type2num_dict = {}\n",
    "            i = 0\n",
    "            j = 0\n",
    "            for line in lines:\n",
    "                if line[-1:] == \"\\n\":\n",
    "                    line = line[:-1]\n",
    "                \n",
    "                phon, type = line.split(\" \")\n",
    "                phonDict[phon] = type\n",
    "                if type not in type2num_dict:\n",
    "                    type2num_dict[type] = j \n",
    "                    j += 1\n",
    "                if phon not in phon2num_dict:\n",
    "                    phon2num_dict[phon] = i\n",
    "                    i += 1\n",
    "            return phonDict, phon2num_dict, type2num_dict\n",
    "\n",
    "        # get phonDict and phon2num\n",
    "        with open(\"phoncode_dict.txt\") as file:\n",
    "            self.phonDict, self.phon2num, self.type2num = get_phonDict(file)\n",
    "\n",
    "\n",
    "    def getMetadata(self, doshuffle=True):\n",
    "        ''' \n",
    "        input\n",
    "            doshuffle: shuffle the csv\n",
    "        '''\n",
    "        self.metadata = pd.read_csv(self.metadataCSVpath)\n",
    "\n",
    "        # if doshuffle:\n",
    "        #     self.metadata = shuffle(self.metadata)\n",
    "\n",
    "        self.metadata = self.metadata.query(\"is_converted_audio == True or is_phonetic_file == True\")\n",
    "        self.metadataWave = self.metadata.query(\"is_converted_audio == True\")\n",
    "        self.metadata.reset_index(drop=True, inplace=True)\n",
    "        self.metadataWave.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "    \n",
    "    def load_audio(self, n=10):\n",
    "        ''' \n",
    "        load audio into MFCC and get phoncode labels \n",
    "        '''\n",
    "        def get_label(file):\n",
    "            ''' \n",
    "            input \n",
    "                file: phonocde label file of an audio\n",
    "            out\n",
    "                label: list of (start_time, end_time, phoncode) (time in unit of wave frames)\n",
    "            '''\n",
    "            lines = file.readlines()\n",
    "            label = []\n",
    "            for line in lines:\n",
    "                if line[-1:] == \"\\n\":\n",
    "                    line = line[:-1]\n",
    "                \n",
    "                s, e, l  = line.split(\" \")\n",
    "                label.append([float(s),float(e), l])\n",
    "            return np.array(label)\n",
    "        \n",
    "        def get_phoncode(t, label):\n",
    "            ''' \n",
    "            input\n",
    "                t: time stamps for MFCC\n",
    "                label: phoncode labeling of the audio cooresp to the t\n",
    "            output\n",
    "                phoncode: phoncode labeling for each time stamp (-1 if not found)\n",
    "            '''\n",
    "            phoncode = []\n",
    "            phoncodeType = []\n",
    "            phoncodeBinary = []\n",
    "            for i, x in enumerate(t):\n",
    "                flag = True\n",
    "                for s,e,p in label:\n",
    "                    if x >= float(s) and x < float(e):\n",
    "                        phoncode.append(self.phon2num[p])\n",
    "                        if self.phonDict[p] == \"Vowels\":\n",
    "                            phoncodeBinary.append(1)\n",
    "                        else:\n",
    "                            phoncodeBinary.append(0)\n",
    "                        phoncodeType.append(self.type2num[self.phonDict[p]])\n",
    "                        flag = False\n",
    "                if flag:\n",
    "                    phoncode.append(-1)\n",
    "                    phoncodeBinary.append(0)\n",
    "                    phoncodeType.append(-1)\n",
    "            return phoncode, phoncodeBinary, phoncodeType\n",
    "        \n",
    "        i = 0   # number of audios counter\n",
    "        while i != n:\n",
    "            audio_fn = self.dirPath + \"data/\" + self.metadataWave[\"path_from_data_dir\"][i]\n",
    "            Phn_fn = audio_fn[:-8] + \".PHN\"\n",
    "            with open(Phn_fn) as file:\n",
    "                label = get_label(file)\n",
    "                fs, t, MFCC = mfcc(audio_fn)\n",
    "                # fs, t, MFCC = STFT(audio_fn)\n",
    "                self.sr = fs\n",
    "                self.audio_MFCC.append(MFCC.T)\n",
    "                self.audio_t.append(t*self.sr)\n",
    "                self.audio_Phoncode.append(label)\n",
    "                phonNum, binaryNum, typeNum = get_phoncode(t*self.sr, label)\n",
    "                self.audio_t_labels.append(phonNum)\n",
    "                self.audio_t_labels_type.append(typeNum)\n",
    "                self.audio_t_labels_binary.append(binaryNum)\n",
    "                i += 1\n",
    "            \n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "TIMIT_PATH = \"TIMIT\"\n",
    "AUDIO_NUM = 500\n",
    "size = 100"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "TIMIT = TIMIT(TIMIT_PATH)\n",
    "TIMIT.getMetadata()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print(len(TIMIT.metadata))\n",
    "TIMIT.metadataWave.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6300\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>test_or_train</th>\n",
       "      <th>dialect_region</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>path_from_data_dir</th>\n",
       "      <th>path_from_data_dir_windows</th>\n",
       "      <th>is_converted_audio</th>\n",
       "      <th>is_audio</th>\n",
       "      <th>is_word_file</th>\n",
       "      <th>is_phonetic_file</th>\n",
       "      <th>is_sentence_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SI681.WAV.wav</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SI681.WAV.wav</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SI681.WAV.wav</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SI1311.WAV.wav</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SI1311.WAV.wav</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.WAV.wav</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SX141.WAV.wav</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SX141.WAV.wav</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SX141.WAV.wav</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SX51.WAV.wav</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SX51.WAV.wav</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SX51.WAV.wav</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SX411.WAV.wav</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SX411.WAV.wav</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SX411.WAV.wav</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index test_or_train dialect_region speaker_id        filename  \\\n",
       "0    1.0         TRAIN            DR4      MMDM0   SI681.WAV.wav   \n",
       "1    7.0         TRAIN            DR4      MMDM0  SI1311.WAV.wav   \n",
       "2   11.0         TRAIN            DR4      MMDM0   SX141.WAV.wav   \n",
       "3   14.0         TRAIN            DR4      MMDM0    SX51.WAV.wav   \n",
       "4   24.0         TRAIN            DR4      MMDM0   SX411.WAV.wav   \n",
       "\n",
       "               path_from_data_dir         path_from_data_dir_windows  \\\n",
       "0   TRAIN/DR4/MMDM0/SI681.WAV.wav   TRAIN\\\\DR4\\\\MMDM0\\\\SI681.WAV.wav   \n",
       "1  TRAIN/DR4/MMDM0/SI1311.WAV.wav  TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.WAV.wav   \n",
       "2   TRAIN/DR4/MMDM0/SX141.WAV.wav   TRAIN\\\\DR4\\\\MMDM0\\\\SX141.WAV.wav   \n",
       "3    TRAIN/DR4/MMDM0/SX51.WAV.wav    TRAIN\\\\DR4\\\\MMDM0\\\\SX51.WAV.wav   \n",
       "4   TRAIN/DR4/MMDM0/SX411.WAV.wav   TRAIN\\\\DR4\\\\MMDM0\\\\SX411.WAV.wav   \n",
       "\n",
       "  is_converted_audio is_audio is_word_file is_phonetic_file is_sentence_file  \n",
       "0               True     True        False            False            False  \n",
       "1               True     True        False            False            False  \n",
       "2               True     True        False            False            False  \n",
       "3               True     True        False            False            False  \n",
       "4               True     True        False            False            False  "
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "TIMIT.load_audio(AUDIO_NUM)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "class Phoncode_Classifier():\n",
    "    def __init__(self, data, labels):\n",
    "        self.X = []     # audio in whatever from\n",
    "        self.y = []     # phoncode labels\n",
    "        \n",
    "        # each audio will have different size, concate them together\n",
    "        for i, x in enumerate(data):\n",
    "            self.X += list(x)\n",
    "            self.y += list(labels[i])\n",
    "        self.X = np.array(self.X)\n",
    "        self.y = np.array(self.y)\n",
    "\n",
    "        self.model = None           # classification model\n",
    "        self.prediction = None      # prediction\n",
    "\n",
    "        self.PCA = -1\n",
    "\n",
    "        print(\"X\", np.shape(self.X))\n",
    "        print(\"y\", np.shape(self.y))\n",
    "\n",
    "    \n",
    "    def train(self, classifier=\"SVM\", PCAdim=-1):\n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        if PCAdim != -1:\n",
    "            self.PCA = PCAdim\n",
    "            X = PCA(n_components=PCAdim).fit(self.X.T).components_\n",
    "            X = X.T\n",
    "        if classifier == \"MLP\":\n",
    "            self.model = MLPClassifier().fit(X, y)\n",
    "        if classifier == \"NB\":\n",
    "            self.model = GaussianNB().fit(X, y)\n",
    "        else:    \n",
    "            self.model = svm.SVC().fit(X, y)\n",
    "\n",
    "        \n",
    "\n",
    "    def predict(self, X_test):\n",
    "        test_set = []\n",
    "        for i,x in enumerate(X_test):\n",
    "            test_set += list(x)\n",
    "        test_set = np.array(test_set) \n",
    "        if self.PCA != -1:\n",
    "            test_set = PCA(n_components=self.PCA).fit(test_set.T).components_\n",
    "            test_set = test_set.T\n",
    "        self.prediction = self.model.predict(test_set)\n",
    "        return self.prediction\n",
    "\n",
    "    def get_ACC(self, y_label):\n",
    "        label = []\n",
    "        for i, y in enumerate(y_label):\n",
    "            label += list(y)\n",
    "        \n",
    "        acc = len(np.where((self.prediction - label) == 0)[0])/len(self.prediction)\n",
    "        print(\"Accuracy:\", acc)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "phonClassifier = Phoncode_Classifier(TIMIT.audio_MFCC[:size], TIMIT.audio_t_labels_binary[:size])\n",
    "phonClassifier.train(classifier = \"SVM\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X (5170, 100)\n",
      "y (5170,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "np.shape(TIMIT.audio_MFCC[2])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(51, 100)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "pred = phonClassifier.predict(TIMIT.audio_MFCC[size:])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "phonClassifier.get_ACC(TIMIT.audio_t_labels_binary[size:])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.8254558065794689\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "from hmmlearn import hmm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "PCA_Train = PCA(n_components=100).fit(phonClassifier.X.T).components_\n",
    "HMM = hmm.GaussianHMM(n_components=2, covariance_type=\"full\", n_iter=200)\n",
    "HMM.fit(PCA_Train.T)\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GaussianHMM(covariance_type='full', n_components=2, n_iter=200)"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "test_set = []\n",
    "for i,x in enumerate(TIMIT.audio_MFCC[size:]):\n",
    "    test_set += list(x)\n",
    "test_set = np.array(test_set) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "PCA_Test = PCA(n_components=100).fit(test_set.T).components_\n",
    "hmm_pred = HMM.predict(PCA_Test.T)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "hmm_pred"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int32)"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "label = []\n",
    "for i, y in enumerate(TIMIT.audio_t_labels_binary[size:]):\n",
    "    label += list(y)\n",
    "\n",
    "acc = len(np.where((hmm_pred - label) == 0)[0])/len(hmm_pred)\n",
    "print(\"Accuracy:\", acc)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.6260404280618311\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}